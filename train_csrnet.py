import os
import cv2
import numpy as np
from tqdm import tqdm
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Conv2D, BatchNormalization
from tensorflow.keras.applications import VGG16
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# === Caminhos ===
IMG_DIR = 'part_B/train_data/images'
DENSITY_DIR = 'part_B/train_data/density_maps'
IMG_SIZE = 224
TARGET_SIZE = 28  # CSRNet com sa√≠da 1/8 de 224


# === Leitura dos dados ===
X, Y = [], []
for filename in tqdm(sorted(os.listdir(IMG_DIR))):
    if not filename.endswith('.jpg'):
        continue
    img_path = os.path.join(IMG_DIR, filename)
    den_path = os.path.join(DENSITY_DIR, filename.replace('.jpg', '.npy'))

    if not os.path.exists(den_path):
        continue

    img = cv2.imread(img_path)
    if img is None:
        continue
    dens = np.load(den_path).astype('float32')

    # üîç DEBUG: ver tamanho original
    if dens.shape != (TARGET_SIZE, TARGET_SIZE):
        print(f"üîÅ Redimensionar {filename} de {dens.shape} para {TARGET_SIZE}x{TARGET_SIZE}")

    # üîß For√ßa sempre o resize para garantir compatibilidade
    dens_resized = cv2.resize(dens, (TARGET_SIZE, TARGET_SIZE), interpolation=cv2.INTER_CUBIC)
    dens_resized *= (np.sum(dens) / np.sum(dens_resized) + 1e-8)  # evita divis√£o por zero

    X.append(img)
    Y.append(dens_resized)


X = np.array(X)
Y = np.expand_dims(np.array(Y), axis=-1)
print(f"‚úÖ Dados carregados: {X.shape[0]} imagens")

# === Separar treino e valida√ß√£o ===
X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)

# === Modelo CSRNet ===
def build_csrnet(input_shape=(224, 224, 3)):
    vgg = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)
    for layer in vgg.layers:
        layer.trainable = False

    x = vgg.output
    for filters, dilation in zip([512, 512, 512, 256, 128, 64], [2, 2, 2, 2, 2, 2]):
        x = Conv2D(filters, (3, 3), dilation_rate=dilation, activation='relu', padding='same')(x)
        x = BatchNormalization()(x)

    output = Conv2D(1, (1, 1), activation='relu', padding='same')(x)  # ativa√ß√£o alterada para relu
    model = Model(inputs=vgg.input, outputs=output)
    model.compile(optimizer=Adam(1e-4), loss=tf.keras.losses.LogCosh(), metrics=['mse'])
    return model

model = build_csrnet()

# === Data Augmentation ===
datagen = ImageDataGenerator(horizontal_flip=True, rotation_range=10, zoom_range=0.1)

# === Callbacks ===
early_stop = EarlyStopping(patience=5, restore_best_weights=True, monitor='val_loss')
checkpoint = ModelCheckpoint('melhor_csrnet.h5', save_best_only=True, monitor='val_loss', mode='min', verbose=1)
lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)

# === Treino ===
history = model.fit(
    datagen.flow(X_train, Y_train, batch_size=4),
    validation_data=(X_val, Y_val),
    epochs=50,
    callbacks=[early_stop, checkpoint, lr_scheduler]
)


# === Gr√°fico da perda ===
plt.figure()
plt.plot(history.history['loss'], label='Train LogCosh')
plt.plot(history.history['val_loss'], label='Val LogCosh')
plt.xlabel('√âpocas')
plt.ylabel('Erro')
plt.title('Evolu√ß√£o da Perda (LogCosh)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.savefig("grafico_csrnet.png")
plt.show()

print("Shape final das imagens:", X.shape)      # (400, 224, 224, 3)
print("Shape final dos mapas:", Y.shape)        # (400, 28, 28, 1)

print(f"Imagem: {img.shape}, Mapa: {dens.shape}")
